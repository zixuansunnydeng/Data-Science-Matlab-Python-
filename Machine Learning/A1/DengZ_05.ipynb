{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DengZ_05.ipynb","provenance":[{"file_id":"1U_CHpuChhCQzWit9qcN4BjLpHB2cd6fB","timestamp":1622782630684},{"file_id":"1e7Bmd2ACvB7TDUyu7SWVivbOatmJbICI","timestamp":1622751942516},{"file_id":"1IgrabRnbdaOqPQhhMsVRPChxMTQ0BujH","timestamp":1622684953159},{"file_id":"1boMa2tAqkd6AEgT2F7JG04KaStASqCFk","timestamp":1622680091737},{"file_id":"1ZGrr6c8KnW1LsIcMnJaFMTGu4NA1pw6Z","timestamp":1622584681158}],"collapsed_sections":[],"authorship_tag":"ABX9TyN3l2Foa4DibN06LNnSX9YH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"3wbWs2-fCfZR"},"source":["## Student: Deng, Zixuan (V00971633)\n","# Problem 5 Decision speed [20 points; only for CSC 503]"]},{"cell_type":"markdown","metadata":{"id":"Bu1eS8qUCkL6"},"source":["## Question:\n","By default, decision stump learning requires O(ndk) to find the optimal stump, where n is the\n","number of samples, d number of dimensions (a.k.a. features), and k the number of thresholds (or\n","categories per feature, if a feature is categorical). Can this be improved? If so, what would be the new complexity bound? If not, why? You will need to provide formal proof regardless of your answer.  "]},{"cell_type":"markdown","metadata":{"id":"dXDxPVT3YvTh"},"source":["In my opinion, therea are three cases during decision stump learning steps: \n","- All features have large amount of discrete values, k is very large. Then the complexity of decision stump learning is still $O(ndk)$\n","- All features are binary? \n","  - in this case k = 2, and the complexity becomes $O(nd)$, k is a constant now. \n","- All features are numerical with unique values. Then the complexity will be $O(n^2d)$ \n","\n","We can see that the number of k will change the decision stump leanring speed a lot. To have further increase of the speed, from $O(nd)$ to a better complexity, we could sort each feature. There is an example, that for $x>1$ and $x>5$, we will have the same decision. Then the complexity become $O(dnlogn)$. The sorting cost is $O(nlogn)$ each feature. "]}]}