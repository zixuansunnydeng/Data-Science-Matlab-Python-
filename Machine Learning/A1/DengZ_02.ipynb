{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DengZ_02.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyObIgrwYSYx+q5QY2qUq2c/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"3wbWs2-fCfZR"},"source":["## Student: Deng, Zixuan (V00971633)\n","# Problem 2"]},{"cell_type":"markdown","metadata":{"id":"Bu1eS8qUCkL6"},"source":["Implement ID3 decision-tree inference algorithm from scratch and infer a decision tree from the\n","cleaned-up US elections dataset (elections clean.csv) that you have generated in Problem 1."]},{"cell_type":"code","metadata":{"id":"rbVJ1XlmCt8y","executionInfo":{"status":"ok","timestamp":1623045195224,"user_tz":420,"elapsed":132,"user":{"displayName":"Sunny Deng","photoUrl":"","userId":"12309281276212380947"}}},"source":["import pandas as pd\n","import numpy as np\n","import random\n","np.random.seed(1337)\n","random.seed(1337)\n","\n","# Plotting support\n","from matplotlib import pyplot as plt\n","from plotnine import *\n","# Standard libraries\n","import pandas as pd\n","import sklearn as sk"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dlg8jycYQXcc"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WC0g-i-xCxsQ"},"source":["## 1. [ID3; 40 points] \n","Implement ID3 from scratch. Use entropy-based split criteria. Only split on categorical featuresâ€” do not use continuous features for splitting"]},{"cell_type":"code","metadata":{"id":"Z5V5mOZBDCpR","executionInfo":{"status":"ok","timestamp":1623045465088,"user_tz":420,"elapsed":133,"user":{"displayName":"Sunny Deng","photoUrl":"","userId":"12309281276212380947"}}},"source":["original_data = pd.read_csv('elections_clean.csv', header=0,index_col=0)\n","df = pd.read_csv('elections_clean.csv', header=0,index_col=0)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"OaH9Ju5yCwaR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623045467087,"user_tz":420,"elapsed":129,"user":{"displayName":"Sunny Deng","photoUrl":"","userId":"12309281276212380947"}},"outputId":"9b7464e7-c72b-48ea-c0a2-b4ac0afab2cb"},"source":["df.shape"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3145, 22)"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":428},"id":"al6ZM7Vy3JLx","executionInfo":{"status":"ok","timestamp":1623045467852,"user_tz":420,"elapsed":144,"user":{"displayName":"Sunny Deng","photoUrl":"","userId":"12309281276212380947"}},"outputId":"a0838afb-cf18-4cf8-b75c-7c01dda5fbc3"},"source":["df.head()"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Votes</th>\n","      <th>UnemploymentRate</th>\n","      <th>HouseholdIncome</th>\n","      <th>PerCapitaIncome</th>\n","      <th>PovertyLevel</th>\n","      <th>DeepPovertyLevel</th>\n","      <th>Population</th>\n","      <th>Area</th>\n","      <th>PopDensity</th>\n","      <th>MaleRate</th>\n","      <th>FemaleRate</th>\n","      <th>Turnout</th>\n","      <th>Democrat</th>\n","      <th>State</th>\n","      <th>County</th>\n","      <th>Education</th>\n","      <th>Religion</th>\n","      <th>Young</th>\n","      <th>Adult</th>\n","      <th>Old</th>\n","      <th>EthnicMale</th>\n","      <th>EthnicFemale</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>7471</td>\n","      <td>0.032</td>\n","      <td>0.687669</td>\n","      <td>0.536632</td>\n","      <td>0.162</td>\n","      <td>0.049330</td>\n","      <td>-0.303817</td>\n","      <td>3.607604</td>\n","      <td>-0.151766</td>\n","      <td>0.4831</td>\n","      <td>0.498326</td>\n","      <td>0.022362</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>13</td>\n","      <td>only high school diploma</td>\n","      <td>Other Misc</td>\n","      <td>0.25037</td>\n","      <td>0.584595</td>\n","      <td>0.096915</td>\n","      <td>White Male</td>\n","      <td>White Female</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7471</td>\n","      <td>0.038</td>\n","      <td>1.756284</td>\n","      <td>1.515032</td>\n","      <td>0.099</td>\n","      <td>0.042878</td>\n","      <td>-0.296080</td>\n","      <td>3.374070</td>\n","      <td>-0.151244</td>\n","      <td>0.4831</td>\n","      <td>0.498326</td>\n","      <td>0.013102</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>16</td>\n","      <td>only high school diploma</td>\n","      <td>Catholic</td>\n","      <td>0.25037</td>\n","      <td>0.584595</td>\n","      <td>0.096915</td>\n","      <td>White Male</td>\n","      <td>White Female</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>7471</td>\n","      <td>0.050</td>\n","      <td>2.319570</td>\n","      <td>2.182969</td>\n","      <td>0.100</td>\n","      <td>0.039032</td>\n","      <td>0.619196</td>\n","      <td>0.196708</td>\n","      <td>-0.052741</td>\n","      <td>0.4831</td>\n","      <td>0.498326</td>\n","      <td>0.000250</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>20</td>\n","      <td>some college or associate's degree</td>\n","      <td>Christian Generic</td>\n","      <td>0.25037</td>\n","      <td>0.584595</td>\n","      <td>0.096915</td>\n","      <td>White Male</td>\n","      <td>White Female</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>7471</td>\n","      <td>0.144</td>\n","      <td>-0.110505</td>\n","      <td>-0.909921</td>\n","      <td>0.238</td>\n","      <td>0.086448</td>\n","      <td>-0.259464</td>\n","      <td>11.578651</td>\n","      <td>-0.151766</td>\n","      <td>0.4831</td>\n","      <td>0.498326</td>\n","      <td>0.004163</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>50</td>\n","      <td>only high school diploma</td>\n","      <td>Catholic</td>\n","      <td>0.25037</td>\n","      <td>0.584595</td>\n","      <td>0.096915</td>\n","      <td>White Male</td>\n","      <td>White Female</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>7471</td>\n","      <td>0.092</td>\n","      <td>2.333129</td>\n","      <td>2.271372</td>\n","      <td>0.095</td>\n","      <td>0.048682</td>\n","      <td>-0.310672</td>\n","      <td>-0.083883</td>\n","      <td>-0.150838</td>\n","      <td>0.4831</td>\n","      <td>0.498326</td>\n","      <td>0.083756</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>60</td>\n","      <td>some college or associate's degree</td>\n","      <td>Catholic</td>\n","      <td>0.25037</td>\n","      <td>0.584595</td>\n","      <td>0.096915</td>\n","      <td>White Male</td>\n","      <td>White Female</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Votes  UnemploymentRate  HouseholdIncome  ...       Old  EthnicMale  EthnicFemale\n","0   7471             0.032         0.687669  ...  0.096915  White Male  White Female\n","1   7471             0.038         1.756284  ...  0.096915  White Male  White Female\n","2   7471             0.050         2.319570  ...  0.096915  White Male  White Female\n","3   7471             0.144        -0.110505  ...  0.096915  White Male  White Female\n","4   7471             0.092         2.333129  ...  0.096915  White Male  White Female\n","\n","[5 rows x 22 columns]"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"rpR0XShXAQk4"},"source":["Approach:\n","1. start from root, select the best split based on the best information gain. \n","2. Loop all features and over all thresholds. Thresholds are all possible features values. \n","3. build tree recursively. \n","4. Stop condition: max depth, min samples at node. \n","\n","\n","Two Class\n","- Node Class\n","  - \n","- Tree Class\n","  - define: root, min sample split, max depth\n","  - entropy calculation\n","  - split tree\n","\n","\n","Some functions required: \n","- "]},{"cell_type":"markdown","metadata":{"id":"UmeHA5tB9cTW"},"source":["I get some ideas from here: https://towardsdatascience.com/id3-decision-tree-classifier-from-scratch-in-python-b38ef145fd90\n","\n"]},{"cell_type":"code","metadata":{"id":"WR0oA4JJ9a-Q","executionInfo":{"status":"ok","timestamp":1623045657279,"user_tz":420,"elapsed":340,"user":{"displayName":"Sunny Deng","photoUrl":"","userId":"12309281276212380947"}}},"source":["from collections import Counter\n","\n","\n","class Node:\n","    def __init__(self, feature = None, threshold=None, left_child = None, value = None, right_child = None):\n","        self.feature = feature\n","        self.threshold = threshold\n","        self.left_child = left_child\n","        self.value = value\n","        self.right_child = right_child\n","\n","\n","class DecisionTree:\n","    def __init__(self, best_split, best_split_threshold, left_children, right_children):\n","        # self.min_samples_split = min_samples_split \n","        # self.max_depth = max_depth\n","        # self.features = features\n","        # self.root = None\n","        self.best_split = best_split \n","        self.best_split_threshold = best_split_threshold, \n","        self.left_chiledren = left_children\n","        self.right_children = right_children\n","\n","\n","def entropy(data):\n","    \n","    if data.shape[1] != 1:\n","        y = data.iloc[:,-1]\n","    else: # for intial entropy calculate for target vector\n","        y = data\n","  \n","    value, counts = np.unique(y, return_counts=True)\n","    probabilities = counts / counts.sum()\n","    entropy = sum(probabilities * -np.log2(probabilities))\n","\n","    return entropy\n","\n","\n","def information_gain(y, feature, threshold):\n","    parent_entropy = entropy(y)\n","    # Get left and right data based on threshold\n","    left, right = split(y,feature,threshold)\n","    prob_l = len(left)/len(y)\n","    prob_r = len(right)/len(y)\n","    child_entropy = prob_l * entropy(left) + prob_r * entropy(right)\n","    infor_gain = parent_entropy - child_entropy\n","\n","    return infor_gain\n","\n","def split(data, feature, threshold):\n","    \"\"\" split current node based on condition. left --> true, right --> false\n","    parameters: features: column index of feature\n","                threshold: the split value\n","    returns: left node, right nodes\n","    \"\"\"\n","    column_value = data.iloc[:,feature]\n","    node_left = data[column_value == threshold]\n","    node_right = data[column_value != threshold]\n","\n","    return node_left, node_right\n","\n","\n","def potential_splits(data):\n","    \"\"\"\n","    parameters: data\n","    returns: potential_splits --->  {'feature': [unique_value1, u_v2, ...]}\n","    \"\"\"\n","\n","    potential_splits = {}\n","    for column_index in range(data.shape[1] - 1):          # excluding the last column which is the label\n","        values = data.iloc[:, column_index]\n","        unique_values = np.unique(values)\n","\n","        # potential_splits --->  {'feature': [unique_value1, u_v2, ...]}\n","        potential_splits[column_index] = unique_value\n","\n","    return potential_splits\n","\n","\n","def best_splits(data, potential_splits):\n","    \"\"\"\n","    parameters: data, potential_splits\n","    return: \n","    feature split: Best split feature \n","    split threshold: in category feature, it's the categories in the feature. \n","    \"\"\"\n","    \n","    max_infor_gain = -float('inf')\n","    for column_id in potential_splits:\n","\n","        print(potential_splits[column_id])\n","        # loop over all potential feature values in data\n","        for value in potential_splits[column_id]:\n","            # split the data into left and right based on condition. \n","            data_left, data_right = split(data,column_id,value)\n","            if len(data_left) > 0 and len(data_right)> 0:\n","                y, left_y, right_y = data.iloc[:, -1], data_left.iloc[:, -1], data_right.iloc[:, -1]\n","                current_information_gain = information_gain(y,left_y, right_y)\n","                if current_information_gain > max_infor_gain: \n","                    best_split = column_id\n","                    best_split_threshold = value \n","\n","    return best_split, best_split_threshold\n","\n","def category_feature(data):\n","    \"\"\"\n","    parameters: data: the whole dataset\n","    return: True if feature is categorical, False if feature is not categorical. \n","    \"\"\"\n","\n","    for column in data.columns: \n","        return data[data[column].dtype == 'object']\n","\n","\n","\n","def leaf(data):\n","\n","    unique_classes, counts_unique_classes = np.unique(label_column, return_counts=True)\n","    index = self.most_common_label(counts_unique_classes)\n","    leaf = unique_classes[index]\n","    return leaf\n","\n","def impurity(data):\n","\n","    if data.shape[1] != 1:\n","        y = data.iloc[:,-1]\n","    else: \n","        y = data\n","    unique_values = np.unique(y)\n","    if unique_values == 1:\n","      return True\n","    else: \n","      return False\n","\n","\n","def most_common_label(y):\n","    return Counter(y)._most_common(1)[0][0]\n","\n","\n","def build_tree(data, depth=0, max_depth = 3):\n","\n","    data = category_feature(data)\n","    # X, y = data.iloc[:,:-1], data.iloc[:,:-1]\n","\n","    # n_samples = data.shape[0]\n","    # if impurity(data):\n","    #   return leaf(data)\n","    \n","    # elif:  \n","\n","    # stop criteria\n","    if depth >= max_depth or impurity(data):\n","        value = most_common_label(data)\n","\n","    else:\n","\n","        best_split, best_split_threshold = self.best_splits(data)\n","        data_left, data_right = self.split(data,best_split,best_split_threshold)\n","\n","        left_children = self.build_tree(data_left, depth + 1)\n","        right_children = self.build_tree(data_right, depth + 1)\n","\n","        return Node(best_split, best_split_threshold, left_chiledren, right_children)\n","        # DecisionTree(min_samples_split = 2, max_depth = 100, best_split, best_split_threshold , left_children, right_children, root = None)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BEsRMfIrCNdT","executionInfo":{"status":"ok","timestamp":1623045661104,"user_tz":420,"elapsed":160,"user":{"displayName":"Sunny Deng","photoUrl":"","userId":"12309281276212380947"}},"outputId":"2d487802-e42c-4498-858a-2cd14b188148"},"source":["information_gain(df, 15, \"only high school diploma\")"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.0005802988187762481"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"k1odf35fDFls"},"source":["## 2. [Boundary; 10 points] \n","Plot the decision boundary made by the tree! You can use the (State,\n","County) tuple as the x-coordinate, and the most prominent feature (the root of the decision\n","tree) as the y-coordinate. Colour (obviously) corresponds to the sample label."]},{"cell_type":"code","metadata":{"id":"HasBQy0oDJs8"},"source":[""],"execution_count":null,"outputs":[]}]}